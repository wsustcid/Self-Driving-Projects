1
00:00:00,520 --> 00:00:03,960
With that out of the way,
let's go back to training models.

2
00:00:03,960 --> 00:00:07,010
Training logistic regression
using gradient descent is great.

3
00:00:07,010 --> 00:00:07,640
For one thing,

4
00:00:07,640 --> 00:00:10,900
you're directly optimizing the error
measure that you care about.

5
00:00:10,900 --> 00:00:12,060
That's always a great idea.

6
00:00:12,060 --> 00:00:15,920
And that's why in practice,
a lot of machine learning research

7
00:00:15,920 --> 00:00:18,239
is about designing the right
lost function to optimize.

8
00:00:19,480 --> 00:00:22,580
But as you might experienced if you've
run the model in the assignments,

9
00:00:22,580 --> 00:00:23,840
it's got problems.

10
00:00:23,840 --> 00:00:26,430
The biggest one is that it's
very difficult to scale.

