1
00:00:00,830 --> 00:00:02,240
Here's an example.

2
00:00:02,240 --> 00:00:05,740
Imagine your network is
a stack of simple operations.

3
00:00:05,740 --> 00:00:09,020
Like in your transforms,
whatever you want.

4
00:00:10,110 --> 00:00:15,990
Some have parameters like the matrix
transforms, some don't like the rellers.

5
00:00:15,990 --> 00:00:18,040
When you apply your
data to some input x,

6
00:00:18,040 --> 00:00:21,790
you have data flowing through
the stack up to your predictions y.

7
00:00:21,790 --> 00:00:25,820
To compute the derivatives, you create
another graph that looks like this.

8
00:00:25,820 --> 00:00:30,220
The data in the new graph flows
backwards through the network,

9
00:00:30,220 --> 00:00:35,000
get's combined using the chain rule that
we saw before and produces gradients.

10
00:00:35,000 --> 00:00:38,350
That graph can be derived completely
automatically from the individual

11
00:00:38,350 --> 00:00:40,260
operations in your network.

12
00:00:40,260 --> 00:00:43,348
So most deep learning frameworks
will just do it for you.

13
00:00:43,348 --> 00:00:48,200
This is called back-propagation,
and it's a very powerful concept.

14
00:00:48,200 --> 00:00:51,770
It makes computing derivatives of
complex function very efficient

15
00:00:51,770 --> 00:00:56,250
as long as the function is made up of
simple blocks with simple derivatives.

16
00:00:56,250 --> 00:01:00,910
Running the model up to the predictions
is often call the forward prop, and

17
00:01:00,910 --> 00:01:04,190
the model that goes backwards
is called the back prop.

18
00:01:04,190 --> 00:01:07,290
So, to recap,
to run stochastic gradient descent,

19
00:01:07,290 --> 00:01:11,220
for every single little batch of
your data in your training set,

20
00:01:11,220 --> 00:01:14,900
you're going to run the forward prop,
and then the back prop.

21
00:01:14,900 --> 00:01:19,270
And that will give you gradients for
each of your weights in your model.

22
00:01:19,270 --> 00:01:21,950
Then you're going to apply those
gradients with the learning weights

23
00:01:21,950 --> 00:01:24,710
to your original weights,
and update them.

24
00:01:24,710 --> 00:01:28,200
And you're going to repeat that
all over again, many, many times.

25
00:01:28,200 --> 00:01:31,610
This is how your entire
model gets optimized.

26
00:01:31,610 --> 00:01:34,610
I am not going to go through more
of the maths of what's going on in

27
00:01:34,610 --> 00:01:35,910
each of those blocks.

28
00:01:35,910 --> 00:01:38,780
Because, again, you don't typically
have to worry about that, and

29
00:01:38,780 --> 00:01:42,270
it's essentially the chain rule,
but keep in mind, this diagram.

30
00:01:42,270 --> 00:01:45,730
In particular each block of
the back prop often takes about

31
00:01:45,730 --> 00:01:50,395
twice the memory that's needed for
prop and twice the compute.

32
00:01:50,395 --> 00:01:52,520
That's important when you
want to size your model and

33
00:01:52,520 --> 00:01:53,940
fit it in memory for example.
