1
00:00:00,000 --> 00:00:01,980
In the first code cell we load

2
00:00:01,980 --> 00:00:05,515
the MNIST data set which comes pre-installed with tensor flow.

3
00:00:05,515 --> 00:00:09,160
Then we store the training validation and test sets.

4
00:00:09,160 --> 00:00:11,910
Next, we verify that the number of images in

5
00:00:11,910 --> 00:00:15,265
each set matches the number of labels in the same set.

6
00:00:15,265 --> 00:00:16,740
Then, we print out the shape of

7
00:00:16,740 --> 00:00:20,340
one image so that we know what the dimensions of the data are.

8
00:00:20,340 --> 00:00:23,430
Finally, we print out the size of each set.

9
00:00:23,430 --> 00:00:24,850
When we run the code,

10
00:00:24,850 --> 00:00:28,500
we see that the training set has 55,000 images.

11
00:00:28,500 --> 00:00:34,130
The validation set has 5,000 images and the test set has 10,000 images.

12
00:00:34,130 --> 00:00:37,570
In the next code cell we transformed the 28 by

13
00:00:37,570 --> 00:00:43,260
28 MNIST images into 32 by 32 images that LeNet can process.

14
00:00:43,260 --> 00:00:48,440
We could do this by using image processing software to scale up each image.

15
00:00:48,440 --> 00:00:52,160
But here, we just pad the images with zeroes around the edges.

16
00:00:52,160 --> 00:00:55,235
This is much faster and it works well.

17
00:00:55,235 --> 00:00:58,950
When we're done, the image shape is 32 by 32

18
00:00:58,950 --> 00:01:02,710
by 1 which is exactly what LeNet takes as input.

19
00:01:02,710 --> 00:01:05,310
It's always a good idea to visualize our data to

20
00:01:05,310 --> 00:01:08,790
make sure that everything actually looks the way we think it does.

21
00:01:08,790 --> 00:01:11,920
In this case, we select a random image from

22
00:01:11,920 --> 00:01:15,970
the training set and we use map plot we have to visualize it.

23
00:01:15,970 --> 00:01:19,170
Then we also print out the label for that image.

24
00:01:19,170 --> 00:01:24,105
Happily, this label matches the image, one-one.

25
00:01:24,105 --> 00:01:26,410
In the next cell we preprocess

26
00:01:26,410 --> 00:01:30,490
the data which in this case just amounts to shuffling the training set.

27
00:01:30,490 --> 00:01:33,670
It's important to shuffle the training data otherwise the ordering

28
00:01:33,670 --> 00:01:37,000
of the data might have a huge effect on how well the network trends.
